// src/hooks/useChatLogic.ts
import { useState, useCallback, useEffect, useRef, useMemo } from 'react';
import { Alert, Platform, PermissionsAndroid } from 'react-native';
import { IMessage } from 'react-native-gifted-chat';
import { DocumentPickerAsset } from 'expo-document-picker';
import Toast from 'react-native-toast-message';
import Clipboard from '@react-native-clipboard/clipboard';
import * as FileSystem from 'expo-file-system/legacy';
import * as Haptics from 'expo-haptics';
import 'text-encoding-polyfill'; // (Ø§ÛŒÙ† Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…Ù‡Ù… Ø§Ø³Øª)

// ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø´Ù…Ø§
import { supabase } from '../lib/supabase';
import { useChat } from '../context/ChatContext';
import { useVoiceRecorder } from '../hooks/useVoiceRecorder';
import { useAttachmentPicker } from '../hooks/useAttachmentPicker';

// Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± ÙØ§Ø² Û± Ø³Ø§Ø®ØªÛŒÙ…
import { createBotMessage, getTimestamp } from '../utils/chatUtils';

// ğŸ›‘ Ø¢Ø¯Ø±Ø³ Ø¨Ú©â€ŒØ§Ù†Ø¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ØªØ¹Ø±ÛŒÙ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
const YOUR_BACKEND_URL = 'https://www.rhynoai.ir';

// ØªØ¹Ø±ÛŒÙ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡
type StagedFileState = {
    asset: DocumentPickerAsset;
    status: 'uploading' | 'uploaded' | 'error';
    uploadedPath?: string;
    error?: string;
};
const JSON_MODELS = [
    "gpt-4o-mini-tts", // (Ù…Ø¯Ù„ TTS Ø´Ù…Ø§)
    "dall-e-3",
    "gpt-5",
    "gpt-5-mini",
    "gpt-4o-transcribe"
];

// ----------------------------------------------------------------
//
//               ğŸ”¥ Ù‡ÙˆÚ© Ø§ØµÙ„ÛŒ Ù…Ù†Ø·Ù‚ Ú†Øª ğŸ”¥
//
// ----------------------------------------------------------------
const TTS_MODEL_ID = "gpt-4o-mini-tts";
export const useChatLogic = () => {

    //
    // ğŸ›‘ === Û±. CONTEXT, STATE & REFS ===
    //
    const {
        session,
        user,
        isLoadingAuth,
        currentChatId,
        setCurrentChatId,
        selectedModel,
        setSelectedModel,
        workspaceId,
        defaultChatSettings,
        workspaceEmbeddingsProvider,
        modelPrompts
    } = useChat();

    // --- State ---
    const [messages, setMessages] = useState<IMessage[]>([]);
    const [stagedFileState, setStagedFileState] = useState<StagedFileState | null>(null);
    const [stagedImage, setStagedImage] = useState<string | null>(null);
    const [isProcessingFile, setIsProcessingFile] = useState(false);
    const [inputKey, setInputKey] = useState('input-key-1');
    const [isSending, setIsSending] = useState(false);
    const [loadingMessages, setLoadingMessages] = useState(true);
    const [initialLoadComplete, setInitialLoadComplete] = useState(false);
    const [currentChatName, setCurrentChatName] = useState<string | null>(null);
    const [editText, setEditText] = useState<string | null>(null);
    const [isTranscribing, setIsTranscribing] = useState(false);
    const [micPermissionGranted, setMicPermissionGranted] = useState(false);

    // --- Refs ---
    const isCreatingChatRef = useRef(false);
    const accumulatedTextRef = useRef('');
    const typingMessageIdRef = useRef<string | number | null>(null);
    const updateIntervalRef = useRef<ReturnType<typeof setInterval> | null>(null);

    //
    // ğŸ›‘ === Û². MEMOIZED VALUES ===
    //
    const { lastUserMessageId, lastBotMessageId } = useMemo(() => {
        const reversedMessages = [...messages].reverse();
        const lastUserMsg = reversedMessages.find(m => m.user._id === 1 && !(m as any).isTyping);
        const lastBotMsg = reversedMessages.find(m => m.user._id === 2 && !(m as any).isTyping);
        return {
            lastUserMessageId: lastUserMsg?._id,
            lastBotMessageId: lastBotMsg?._id,
        };
    }, [messages]);

    const { displayName, firstName } = useMemo(() => {
        const dName = user?.user_metadata?.display_name ||
            user?.user_metadata?.username ||
            user?.email ||
            "Ú©Ø§Ø±Ø¨Ø±";
        const fName = dName.replace(/[0-9]/g, "").split(/[\s@,.;]+/)[0];
        return { displayName: dName, firstName: fName };
    }, [user]);

    const chatSettings = useMemo(() => ({
        model: selectedModel
    }), [selectedModel]);

    const isRealtimeModel = useCallback((modelId: string): boolean => {
        return (
            modelId.includes('realtime') ||
            modelId.includes('gpt-4o-voice')
        );
    }, []);

    //
    // ğŸ›‘ === Û³. CORE FUNCTIONS (Streaming, Fetching, API Calls) ===
    //

    const startStreamingUpdates = useCallback(() => {
        if (updateIntervalRef.current) clearInterval(updateIntervalRef.current);
        updateIntervalRef.current = setInterval(() => {
            if (!typingMessageIdRef.current) return;
            const currentText = accumulatedTextRef.current;
            setMessages(prev =>
                prev.map(msg =>
                    msg._id === typingMessageIdRef.current
                        ? { ...msg, text: currentText.length ? currentText : '' }
                        : msg,
                ),
            );
        }, 200);
    }, [setMessages]); // setMessages

    const stopStreamingUpdates = useCallback((
        isError: boolean = false,
        assistantImage: string | null = null
    ) => {
        if (updateIntervalRef.current) clearInterval(updateIntervalRef.current);
        updateIntervalRef.current = null;

        if (!isError && typingMessageIdRef.current) {
            const finalText = accumulatedTextRef.current;
            setMessages(prev =>
                prev.map(msg =>
                    msg._id === typingMessageIdRef.current
                        ? {
                            ...msg,
                            text: finalText || 'Ù¾Ø§Ø³Ø®ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.',
                            image: assistantImage || undefined,
                            isTyping: false,
                        }
                        : msg,
                ),
            );
        } else if (isError && typingMessageIdRef.current) {
            const errorText = accumulatedTextRef.current || "Ø®Ø·Ø§";
            setMessages(prev =>
                prev.map(msg =>
                    msg._id === typingMessageIdRef.current
                        ? { ...msg, text: errorText, isTyping: false }
                        : msg
                )
            );
        }

        accumulatedTextRef.current = '';
        typingMessageIdRef.current = null;
        setIsSending(false);
    }, [setMessages, setIsSending]); // setMessages, setIsSending

    const fetchMessages = useCallback(async (chatId: string) => {
        if (!chatId) {
            setMessages([]);
            setLoadingMessages(false);
            setInitialLoadComplete(true);
            return;
        }
        setLoadingMessages(true);
        try {
            const { data, error } = await supabase
                .from('messages')
                .select('id, content, role, created_at, model, image_paths, audio_url')
                .eq('chat_id', chatId)
                .order('created_at', { ascending: true });

            if (error) throw error;

            const formattedMessages: IMessage[] = (data || []).map((msg: any) => {
                let textContent = msg.content || '';
                let imageUri: string | undefined = undefined;

                // --- Û±. Ú†Ú© Ú©Ø±Ø¯Ù† image_paths (Ù…Ø³ÛŒØ± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯) ---
                if (msg.image_paths && Array.isArray(msg.image_paths) && msg.image_paths.length > 0) {
                    const path = msg.image_paths[0];
                    if (path && path.startsWith('data:image')) {
                        imageUri = path;
                    } else if (path) {
                        const { data: publicUrlData } = supabase.storage
                            .from('message_images') // <--- Ù†Ø§Ù… Ø¨Ø§Ú©Øª Ø´Ù…Ø§
                            .getPublicUrl(path);   // <--- Ù…Ø³ÛŒØ±ÛŒ Ú©Ù‡ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø®ÙˆØ§Ù†Ø¯ÛŒÙ…
                        imageUri = publicUrlData.publicUrl;
                    }
                }

                // âœ…âœ…âœ…âœ…âœ… Ø´Ø±ÙˆØ¹ Ù…Ù†Ø·Ù‚ Ø¬Ø¯ÛŒØ¯ âœ…âœ…âœ…âœ…âœ…
                const SEPARATOR = '%RHINO_IMAGE_SEPARATOR%';

                // --- Û². Ú†Ú© Ú©Ø±Ø¯Ù† SEPARATOR Ø¯Ø± content (Ù…Ø®ØµÙˆØµ DALL-E) ---
                // (Ø§Ú¯Ø± Ù…Ù†Ø·Ù‚ Û± Ø¹Ú©Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯ØŒ Ø§ÛŒÙ† Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†)
                if (!imageUri && textContent.includes(SEPARATOR)) {
                    const parts = textContent.split(SEPARATOR);
                    textContent = parts[0]?.replace(/%$/, '').trim(); // Ù…ØªÙ† ÙˆØ§Ù‚Ø¹ÛŒ
                    let imageData = parts[1]?.replace(/%$/, '').trim(); // Ø¯Ø§Ø¯Ù‡ Ø¹Ú©Ø³

                    if (imageData?.startsWith('http') || imageData?.startsWith('data:image')) {
                        imageUri = imageData;
                    } else if (imageData && imageData.length > 50) {
                        // Ù‡Ù…Ø§Ù† Ù…Ù†Ø·Ù‚ ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† base64 Ø§Ø² MessageItem
                        const potentialBase64 = imageData.replace(/\n/g, '');
                        if (!potentialBase64.includes(' ')) {
                            imageUri = `data:image/png;base64,${potentialBase64}`;
                        }
                    }
                }
                // --- Û³. ÙØ§Ù„â€ŒØ¨Ú© Ù†Ù‡Ø§ÛŒÛŒ (Ø¨Ø±Ø§ÛŒ Ø¹Ú©Ø³â€ŒÙ‡Ø§ÛŒ base64 Ø®ÛŒÙ„ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ) ---
                else if (!imageUri && msg.role === 'assistant' && textContent.length > 200) {
                    const potentialBase64 = textContent.replace(/\n/g, '');
                    if (!potentialBase64.includes(' ')) {
                        imageUri = `data:image/png;base64,${potentialBase64}`;
                        textContent = ''; // Ù…ØªÙ† Ø±Ø§ Ù¾Ø§Ú© Ú©Ù† Ú†ÙˆÙ† Ø¹Ú©Ø³ Ø§Ø³Øª
                    }
                }

                let fileAssetForMessage: DocumentPickerAsset | null = null;
                if (textContent.includes('(ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡:')) {
                    try {
                        const fileName = textContent.split('(ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡:')[1].split(')')[0];
                        if (fileName) {
                            fileAssetForMessage = { name: fileName } as DocumentPickerAsset;
                        }
                    } catch (e) { }
                }

                return {
                    _id: msg.id,
                    text: textContent,
                    createdAt: new Date(msg.created_at),
                    user: {
                        _id: msg.role === 'user' ? 1 : 2,
                        name: msg.role === 'user' ? 'You' : msg.model || 'Rhyno AI',
                    },
                    image: imageUri,
                    fileAsset: fileAssetForMessage,
                    audio: msg.audio_url || undefined,
                };
            });

            setMessages(formattedMessages);
            setInitialLoadComplete(true);
        } catch (error: any) {
            console.error('Error fetching messages:', error);
            Toast.show({ type: 'error', text1: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§', text2: error.message });
            setInitialLoadComplete(true);
        } finally {
            setLoadingMessages(false);
        }
    }, [supabase]); // supabase

    const callChatAPI = useCallback(async (
        activeChatId: string | undefined,
        messageHistory: any[],
        userMessage: IMessage,
        modelOverride?: string
    ) => {
        console.log("--- [ChatLogic] 1. callChatAPI started. ---"); // ğŸªµ Ù„Ø§Ú¯ Û±

        const { data: { session: freshSession }, error: sessionError } = await supabase.auth.getSession();
        if (sessionError || !freshSession) {
            console.error("--- [ChatLogic] â—ï¸ ERROR: Invalid session. ---");
            stopStreamingUpdates(true, "Ø®Ø·Ø§: Ø¬Ù„Ø³Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª."); // (Ø§Ø² stopStreamingUpdates Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯)
            return;
        }
        const accessToken = freshSession.access_token;

        if (!activeChatId || !user) {
            console.error("--- [ChatLogic] â—ï¸ ERROR: Chat ID or User missing. ---");
            stopStreamingUpdates(true, "Ø®Ø·Ø§: Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†Ø´Ø¯.");
            return;
        }

        const modelForAPI = modelOverride || selectedModel;
        if (!modelForAPI) {
            console.error("--- [ChatLogic] â—ï¸ ERROR: Model not selected. ---");
            stopStreamingUpdates(true, "Ø®Ø·Ø§: Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.");
            return;
        }

        console.log(`--- [ChatLogic] 2. Model selected: ${modelForAPI} ---`); // ğŸªµ Ù„Ø§Ú¯ Û²
        const chatSettingsForAPI = { model: modelForAPI };

        // --- âœ…âœ…âœ… Ù…Ù†Ø·Ù‚ Ø­ÛŒØ§ØªÛŒ ---
        // Û±. Ø¢Ø¯Ø±Ø³ Ù‡Ù…ÛŒØ´Ù‡ Ø«Ø§Ø¨Øª Ø§Ø³Øª (Ø·Ø¨Ù‚ Ø®ÙˆØ§Ø³ØªÙ‡ Ø´Ù…Ø§)
        const endpoint = "/api/chat/openai";

        // Û². ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ… Ú©Ù‡ Ø¢ÛŒØ§ Ù…Ù†ØªØ¸Ø± JSON Ø¨Ø§Ø´ÛŒÙ… ÛŒØ§ Stream
        const isStreaming = !JSON_MODELS.includes(modelForAPI);
        // --- âœ…âœ…âœ… ---

        console.log(`--- [ChatLogic] 3. Decision: isStreaming=${isStreaming}, endpoint=${endpoint} ---`); // ğŸªµ Ù„Ø§Ú¯ Û³

        const url = `${YOUR_BACKEND_URL}${endpoint}`;
        const body = JSON.stringify({
            chatSettings: chatSettingsForAPI,
            messages: messageHistory,
            enableWebSearch: true,
            chat_id: activeChatId,
            is_user_message_saved: false // (Ú©Ù„Ø§ÛŒÙ†Øª Ù…ÙˆØ¨Ø§ÛŒÙ„ Ø®ÙˆØ¯Ø´ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
        });

        if (isStreaming) {

            // --- Ù…Ø³ÛŒØ± Û±: Ø§Ø³ØªØ±ÛŒÙ… Ù…ØªÙ† (Ú©Ø¯ XHR ÙØ¹Ù„ÛŒ Ø´Ù…Ø§) ---
            console.log(`--- [ChatLogic] 4. Executing STREAMING path (XHR) to: ${url} ---`); // ğŸªµ Ù„Ø§Ú¯ Û´ (Ø§Ø³ØªØ±ÛŒÙ…)
            accumulatedTextRef.current = '';
            startStreamingUpdates(); // (ØªØ§Ø¨Ø¹ Ø´Ù…Ø§)

            // (Ú©Ø¯ XHR Ø´Ù…Ø§ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ±ÛŒÙ… Ø¹Ø§Ù„ÛŒ Ø§Ø³Øª)
            return new Promise<void>((resolve, reject) => {
                try {
                    const xhr = new XMLHttpRequest();
                    let seenBytes = 0;
                    xhr.open('POST', url);
                    xhr.setRequestHeader('Authorization', `Bearer ${accessToken}`);
                    xhr.setRequestHeader('Content-Type', 'application/json');

                    xhr.onprogress = () => {
                        const newText = xhr.responseText.substring(seenBytes);
                        accumulatedTextRef.current += newText;
                        seenBytes = xhr.responseText.length;
                    };

                    xhr.onload = async () => {
                        try {
                            if (xhr.status >= 200 && xhr.status < 300) {
                                console.log("--- [ChatLogic] 5. XHR Stream SUCCESS. ---");
                                const finalAssistantText = accumulatedTextRef.current;
                                stopStreamingUpdates(false, null);

                                if (finalAssistantText && activeChatId && user) {
                                    // (Ú©Ø¯ Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ§Ù… Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³)
                                    await supabase.from('messages').insert({
                                        chat_id: activeChatId,
                                        user_id: user.id,
                                        content: finalAssistantText.trim(),
                                        role: 'assistant',
                                        model: modelForAPI,
                                        sequence_number: messages.length,
                                        image_paths: []
                                    });
                                }
                                await supabase.from('chats').update({ updated_at: new Date().toISOString() })
                                    .eq('id', activeChatId)
                                    .eq('user_id', user.id);
                                resolve();

                            } else {
                                const errorText = xhr.responseText || 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ XHR';
                                console.error(`--- [ChatLogic] â—ï¸ 5. XHR Stream FAILED. Status: ${xhr.status} ---`, errorText);
                                accumulatedTextRef.current = `Ø®Ø·Ø§ÛŒ Ø³Ø±ÙˆØ± ${xhr.status}: ${errorText}`;
                                stopStreamingUpdates(true, null);
                                reject(new Error(`Server error: ${xhr.status}`));
                            }
                        } catch (onloadError: any) {
                            console.error("--- [ChatLogic] â—ï¸ ERROR inside XHR onload: ---", onloadError);
                            reject(onloadError);
                        }
                    };
                    xhr.onerror = () => {
                        console.error("--- [ChatLogic] â—ï¸ 5. XHR Network FAILED. ---");
                        accumulatedTextRef.current = `Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ Ø¯Ø± XHR.`;
                        stopStreamingUpdates(true, null);
                        reject(new Error("XHR Network Error"));
                    };
                    xhr.send(body);
                } catch (err: any) {
                    console.error("--- [ChatLogic] â—ï¸ 5. XHR Setup FAILED. ---", err);
                    accumulatedTextRef.current = `Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ: ${err.message}`;
                    stopStreamingUpdates(true, null);
                    reject(err);
                }
            });

        } else {

            // --- Ù…Ø³ÛŒØ± Û²: Ø¯Ø±ÛŒØ§ÙØª JSON (Ø¨Ø±Ø§ÛŒ TTS Ùˆ DALL-E) ---
            console.log(`--- [ChatLogic] 4. Executing JSON path (fetch) to: ${url} ---`); // ğŸªµ Ù„Ø§Ú¯ Û´ (JSON)

            setMessages(prev => prev.map(msg =>
                msg._id === typingMessageIdRef.current ? { ...msg, text: 'Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...' } : msg
            ));

            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${accessToken}`,
                        'Content-Type': 'application/json',
                    },
                    body: body
                });

                console.log(`--- [ChatLogic] 5. JSON Response Status: ${response.status} ---`); // ğŸªµ Ù„Ø§Ú¯ Ûµ

                if (!response.ok) {
                    const errorText = await response.text();
                    console.error(`--- [ChatLogic] â—ï¸ 6. JSON Response FAILED: ${errorText} ---`); // ğŸªµ Ù„Ø§Ú¯ Û¶ (Ø®Ø·Ø§)
                    throw new Error(`Server error ${response.status}: ${errorText}`);
                }

                const data = await response.json();
                console.log("--- [ChatLogic] 6. JSON Response SUCCESS. Data:", data); // ğŸªµ Ù„Ø§Ú¯ Û¶ (Ù…ÙˆÙÙ‚)

                // (Ø¨Ú©â€ŒØ§Ù†Ø¯ Ø´Ù…Ø§ text Ùˆ audioUrl Ø±Ø§ Ø¯Ø± Ø¢Ø¨Ø¬Ú©Øª JSON Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯)
                const newText = data.text || 'Ù¾Ø§Ø³Ø® Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯';
                const newImage = data.imageUrl || undefined;
                const newAudio = data.audioUrl || undefined; // âœ…âœ…âœ… Ø§ÛŒÙ† Ù‡Ù…Ø§Ù† Ú†ÛŒØ²ÛŒ Ø§Ø³Øª Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒÙ…

                console.log(`--- [ChatLogic] 7. Parsed Data: newText=${newText}, newAudio=${newAudio} ---`); // ğŸªµ Ù„Ø§Ú¯ Û·

                // --- Ù¾ÛŒØ§Ù… "Ø¯Ø± Ø­Ø§Ù„ ØªØ§ÛŒÙ¾" Ø±Ø§ Ø¨Ø§ Ù¾ÛŒØ§Ù… Ù†Ù‡Ø§ÛŒÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù† ---
                setMessages(prev =>
                    prev.map(msg =>
                        msg._id === typingMessageIdRef.current
                            ? {
                                ...msg,
                                text: newText,
                                image: newImage,
                                audio: newAudio, // âœ…âœ…âœ… Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø±Ø§ÛŒ Ø±Ù†Ø¯Ø± AudioPlayer Ø³Øª Ù…ÛŒâ€ŒØ´ÙˆØ¯
                                isTyping: false,
                            }
                            : msg,
                    ),
                );

                // --- Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù† ---
                console.log("--- [ChatLogic] 8. Saving assistant message to local DB... ---");
                await supabase
                    .from('messages')
                    .insert({
                        chat_id: activeChatId,
                        user_id: user.id,
                        content: newText,
                        role: 'assistant',
                        model: modelForAPI,
                        sequence_number: messages.length,
                        image_paths: newImage ? [newImage] : [],
                        audio_url: newAudio || null // âœ…âœ…âœ… Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
                    });
                console.log("--- [ChatLogic] 9. Message saved. Updating chat timestamp... ---");

                await supabase
                    .from('chats')
                    .update({ updated_at: new Date().toISOString() })
                    .eq('id', activeChatId)
                    .eq('user_id', user.id);

                console.log("--- [ChatLogic] 10. TTS/JSON Flow COMPLETE. ---");

            } catch (error: any) {
                console.error(`--- [ChatLogic] â—ï¸ ERROR in JSON fetch block: ---`, error); // ğŸªµ Ù„Ø§Ú¯ Ø®Ø·Ø§
                accumulatedTextRef.current = `Ø®Ø·Ø§: ${error.message}`;
                stopStreamingUpdates(true, null); // Ù†Ù…Ø§ÛŒØ´ Ø®Ø·Ø§ Ø¯Ø± UI
            } finally {
                // (Ù…Ø·Ù…Ø¦Ù† Ù…ÛŒâ€ŒØ´ÙˆÛŒÙ… Ú©Ù‡ isSending Ø¯Ø± Ù‡Ø± ØµÙˆØ±Øª false Ù…ÛŒâ€ŒØ´ÙˆØ¯)
                if (typingMessageIdRef.current) {
                    stopStreamingUpdates(false, null);
                }
            }
        }
    }, [
        // (ØªÙ…Ø§Ù… ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒØ¯)
        user,
        selectedModel,
        supabase,
        chatSettings,
        messages,
        startStreamingUpdates,
        stopStreamingUpdates
    ]);

    const uploadFile = useCallback(async (asset: DocumentPickerAsset) => {
        if (!user) return;
        const { data: { session: freshSession }, error: sessionError } = await supabase.auth.getSession();
        if (sessionError || !freshSession) {
            setStagedFileState({ asset, status: 'error', error: 'Ø¬Ù„Ø³Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø±' });
            return;
        }
        const accessToken = freshSession.access_token;

        try {
            const fileBlob = await (await fetch(asset.uri)).blob();
            const filePath = `${user.id}/${Date.now()}_${asset.name}`;
            const edgeFunctionUrl = `https://auisyflifvylebhgwcfe.functions.supabase.co/file-uploader`;

            const uploadResponse = await fetch(edgeFunctionUrl, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${accessToken}`,
                    'Content-Type': asset.mimeType || 'application/octet-stream',
                    'X-File-Path': filePath,
                },
                body: fileBlob,
            });

            const uploadData = await uploadResponse.json();
            if (!uploadResponse.ok) throw new Error(uploadData.error || 'Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§Ù†Ú©Ø´Ù†');

            setStagedFileState({ asset, status: 'uploaded', uploadedPath: filePath });

        } catch (error: any) {
            console.error("File upload failed:", error);
            setStagedFileState({ asset, status: 'error', error: error.message });
        }
    }, [user, supabase]); // user, supabase

    const processUploadedFile = useCallback(async (
        activeChatId: string,
        fileState: StagedFileState
    ): Promise<string | null> => {
        if (!fileState || fileState.status !== 'uploaded' || !user || !workspaceId || !fileState.uploadedPath) {
            Alert.alert("Ø®Ø·Ø§", "Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.");
            return null;
        }

        const { asset, uploadedPath } = fileState;
        const fileName = asset.name;

        setIsProcessingFile(true);
        Toast.show({ type: 'info', text1: 'â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„...', text2: fileName });

        const { data: { session: freshSession }, error: sessionError } = await supabase.auth.getSession();
        if (sessionError || !freshSession) {
            Toast.show({ type: 'error', text1: 'Ø®Ø·Ø§', text2: 'Ø¬Ù„Ø³Ù‡ (session) Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.' });
            setIsProcessingFile(false);
            return null;
        }
        const accessToken = freshSession.access_token;

        try {
            const { data: fileRow, error: insertError } = await supabase
                .from('files')
                .insert({
                    user_id: user.id,
                    name: fileName,
                    type: asset.mimeType || 'application/octet-stream',
                    size: asset.size || 0,
                    file_path: uploadedPath,
                    tokens: 0,
                    description: '',
                })
                .select('id')
                .single();

            if (insertError) throw new Error(`Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: ${insertError.message}`);

            const file_id = fileRow.id;
            const formData = new FormData();
            formData.append('file_id', file_id);
            formData.append('embeddingsProvider', 'openai');

            const processResponse = await fetch(`${YOUR_BACKEND_URL}/api/retrieval/process`, {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${accessToken}` },
                body: formData,
            });

            if (!processResponse.ok) {
                const err = await processResponse.json();
                throw new Error(`Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÙˆØ±: ${err.message || 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡'}`);
            }

            Toast.show({ type: 'success', text1: 'âœ… ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯', text2: fileName });
            return file_id;
        } catch (error: any) {
            console.error("File processing failed:", error);
            Toast.show({ type: 'error', text1: `âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„: ${fileName}`, text2: error.message });
            return null;
        } finally {
            setIsProcessingFile(false);
        }
    }, [user, workspaceId, supabase]); // user, workspaceId, supabase

    //
    // ğŸ›‘ === Û´. USER ACTIONS (Send, Voice, Attachments) ===
    //

    // --- Send Message (The "Orchestrator") ---
    const handleSendMessage = (text: string, modelOverride?: string) => {
        if (isProcessingFile) { return; }
        const fileToProcess = stagedFileState?.status === 'uploaded' ? stagedFileState : null;
        if (!text.trim() && !stagedImage && !fileToProcess) return;
        if (!user || isSending) { return; }
        Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Medium);

        let userMessageText = text.trim();
        let fileAssetForMessage: DocumentPickerAsset | null = null;
        if (fileToProcess) {
            fileAssetForMessage = fileToProcess.asset;
            userMessageText = !userMessageText
                ? `ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡ Ø´Ø¯: ${fileToProcess.asset.name}`
                : `${text.trim()}\n\n(ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡: ${fileToProcess.asset.name})`;
        }

        const newMessage: IMessage & { fileAsset?: DocumentPickerAsset | null } = {
            _id: `user-${Date.now()}`,
            text: userMessageText,
            createdAt: new Date(),
            user: { _id: 1, name: displayName || 'You' },
            image: stagedImage || undefined,
            fileAsset: fileAssetForMessage,
        };

        const typingMessageId = `typing-${Date.now()}`;
        const typingMessage = createBotMessage(typingMessageId, '');
        typingMessageIdRef.current = typingMessageId;


        setIsSending(true);
        setMessages(previousMessages => [...previousMessages, newMessage, typingMessage]);
        setStagedImage(null);
        setStagedFileState(null);
        setEditText(null); // (Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù† Ø­Ø§Ù„Øª Ø§Ø¯ÛŒØª)
        setInputKey(`input-key-${Date.now()}`);

        // --- ASYNC FLOW ---
        (async () => {
            let activeChatId = currentChatId;
            let fileIdsForRetrieval: string[] = [];
            let contextText: string = "";
            const modelToUse = modelOverride || selectedModel;

            try {
                // --- A: Create Chat (if needed) ---
                if (!activeChatId && user) {
                    isCreatingChatRef.current = true;
                    let chatName = text.trim() || (fileToProcess && fileToProcess.asset.name) || (stagedImage && "Ú†Øª ØªØµÙˆÛŒØ±ÛŒ") || "Ú†Øª Ø¬Ø¯ÛŒØ¯";
                    chatName = chatName.split(' ').slice(0, 5).join(' ');

                    const chatDataForAPI = {
                        name: chatName,
                        workspace_id: workspaceId,
                        assistant_id: null,
                        model: modelToUse,
                        context_length: defaultChatSettings[selectedModel]?.MAX_CONTEXT_LENGTH ?? 4096,
                        temperature: defaultChatSettings[selectedModel]?.MAX_TEMPERATURE ?? 1,
                        embeddings_provider: workspaceEmbeddingsProvider || 'openai',
                        include_profile_context: true,
                        include_workspace_instructions: true,
                        prompt: modelPrompts[selectedModel] || "You are a helpful assistant.",
                    };

                    const { data: { session }, error: sessionError } = await supabase.auth.getSession();
                    if (sessionError || !session) throw new Error(sessionError?.message || "User session not found.");

                    const response = await fetch(`${YOUR_BACKEND_URL}/api/chat/create`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': `Bearer ${session.access_token}`
                        },
                        body: JSON.stringify(chatDataForAPI)
                    });

                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(errorData.message || `Failed to create chat (Status: ${response.status})`);
                    }

                    const newChat = await response.json();
                    activeChatId = newChat.id;
                    setCurrentChatId(activeChatId);
                }

                if (!activeChatId) throw new Error("Chat ID is still missing.");
                if (!user) throw new Error("User is not logged in.");

                const { error: tsError } = await supabase
                    .from('chats')
                    .update({ updated_at: new Date().toISOString() })
                    .eq('id', activeChatId)
                    .eq('user_id', user.id);
                if (tsError) console.warn("[Optimistic] Timestamp update failed:", tsError.message);

                // --- B: Process File (if exists) ---
                if (fileToProcess) {
                    const newFileId = await processUploadedFile(activeChatId, fileToProcess);
                    if (newFileId) fileIdsForRetrieval.push(newFileId);
                }

                // --- C: Retrieve Context (if needed) ---
                if (fileIdsForRetrieval.length > 0) {
                    const { data: { session: freshSession }, error: sessionError } = await supabase.auth.getSession();
                    if (sessionError || !freshSession) throw new Error("Ø¬Ù„Ø³Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ");

                    const retrievalResponse = await fetch(`${YOUR_BACKEND_URL}/api/retrieval/retrieve`, {
                        method: 'POST',
                        headers: {
                            'Authorization': `Bearer ${freshSession.access_token}`,
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({ userInput: userMessageText, fileIds: fileIdsForRetrieval })
                    });

                    if (retrievalResponse.ok) {
                        const retrievalData = await retrievalResponse.json();
                        if (retrievalData.fileItems && retrievalData.fileItems.length > 0) {
                            contextText = retrievalData.fileItems.map((item: any) => item.content).join("\n\n");
                        }
                    } else {
                        Toast.show({ type: 'error', text1: 'Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„', text2: 'Ø§Ø¯Ø§Ù…Ù‡ Ú†Øª Ø¨Ø¯ÙˆÙ† Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„...' });
                    }
                }

                // --- D: Build final API message history ---
                const historyForAPI = [...messages, newMessage]; // 'messages' dependency
                let backendMessages = historyForAPI
                    .filter(msg => !(msg.user._id === 2 && msg.text === '...'))
                    .sort((a, b) => getTimestamp(a.createdAt) - getTimestamp(b.createdAt))
                    .map(msg => {
                        // ... (Ù…Ù†Ø·Ù‚ Ø³Ø§Ø®Øª Ø¢Ø¨Ø¬Ú©Øª Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ API - Ú©Ù¾ÛŒ Ø´Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ)
                        const msgWithFile = msg as IMessage & { fileAsset?: DocumentPickerAsset | null };
                        const content: any = [];
                        let textForAPI = msg.text.trim();

                        if (msgWithFile.fileAsset && textForAPI.startsWith('ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡ Ø´Ø¯:')) {
                            textForAPI = `User uploaded a file: ${msgWithFile.fileAsset.name}. Analyze it.`;
                        } else if (msgWithFile.fileAsset) {
                            textForAPI = `${textForAPI}\n\n[File Attached: ${msgWithFile.fileAsset.name}]`;
                        }

                        if (textForAPI) content.push({ type: 'text', text: textForAPI });
                        if (msg.image) {
                            content.push({ type: 'image_url', image_url: { url: msg.image } });
                        }

                        if (content.length === 0) content.push({ type: 'text', text: ' ' });
                        const role = msg.user._id === 1 ? 'user' : 'assistant';
                        if (content.length === 1 && content[0].type === 'text') { return { role: role, content: content[0].text }; }
                        return { role: role, content: content };
                    });

                // --- E: Inject Context ---
                if (contextText) {
                    const contextMessage = {
                        role: "system",
                        content: `Here is relevant context from user-uploaded files:\n\n${contextText}\n\nBased on this context, please answer the user's following message.`
                    };
                    backendMessages.splice(backendMessages.length - 1, 0, contextMessage);
                }

                // --- F: Call Chat API ---
                await callChatAPI(activeChatId, backendMessages, newMessage, modelToUse);

            } catch (error: any) {
                console.error("â›”ï¸ ERROR IN SEND FLOW â›”ï¸", error);
                let errorMessage = error.message;
                if (error.message && error.message.includes("Network request failed")) {
                    errorMessage = "Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡. (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ CORS ÛŒØ§ Ù‚Ø·Ø¹ÛŒ Ø§ÛŒÙ†ØªØ±Ù†Øª)";
                }
                accumulatedTextRef.current = `Ø®Ø·Ø§: ${errorMessage}`;
                stopStreamingUpdates(true, null);
            }
        })();
    }; // (ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø³ÛŒØ§Ø± Ø²ÛŒØ§Ø¯ Ø§Ø³ØªØŒ useCallback Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…)

    // --- Voice Actions ---
    const handleVoiceSubmit = useCallback(async (uri: string, duration: number) => {
        if (!user) return;
        setIsTranscribing(true);

        try {
            const { data: { session: freshSession }, error: sessionError } = await supabase.auth.getSession();
            if (sessionError || !freshSession) throw new Error('Ø¬Ù„Ø³Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø±');
            const accessToken = freshSession.access_token;

            const formData = new FormData();
            formData.append('file', {
                uri: Platform.OS === 'ios' ? uri.replace('file://', '') : uri,
                name: `recording-${Date.now()}.m4a`,
                type: 'audio/m4a',
            } as any);

            const response = await fetch(`${YOUR_BACKEND_URL}/api/transcribe`, {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${accessToken}` },
                body: formData,
            });

            const result = await response.json();
            if (!response.ok || !result.text) throw new Error(result.message || 'Ø®Ø·Ø§ Ø¯Ø± Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ ØµØ¯Ø§');

            const transcribedText = result.text;
            if (selectedModel === 'gpt-4o-transcribe') {
                // âœ…âœ…âœ… Û³. 'audio: uri' Ø±Ø§ Ø¨Ù‡ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
                const userAudioMessage: IMessage & { audio?: string } = {
                    _id: `user-audio-${Date.now()}`,
                    text: `(ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ: ${Math.round(duration / 1000)} Ø«Ø§Ù†ÛŒÙ‡)`,
                    createdAt: new Date(),
                    user: { _id: 1, name: displayName || 'You' },
                    audio: uri, // Û². âœ…âœ…âœ… Ø®Ø· Ø­ÛŒØ§ØªÛŒ: URI ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
                };
                const assistantTextMessage: IMessage = {
                    _id: `bot-transcribe-${Date.now()}`,
                    text: transcribedText,
                    createdAt: new Date(),
                    user: { _id: 2, name: 'Rhyno Transcribe' },
                };
                setMessages(prev => [...prev, userAudioMessage, assistantTextMessage]);
            } else {
                handleSendMessage(transcribedText);
            }
        } catch (error: any) {
            console.error("Voice transcription failed:", error);
            Alert.alert('Ø®Ø·Ø§', 'Ø®Ø·Ø§ Ø¯Ø± Ø±ÙˆÙ†ÙˆÛŒØ³ÛŒ ØµØ¯Ø§: ' + error.message);
        } finally {
            setIsTranscribing(false);
        }
    }, [user, selectedModel, supabase, displayName, handleSendMessage]); // (handleSendMessage is stable)

    const {
        status: recordingStatus,
        handleToggleRecording,
    } = useVoiceRecorder({
        onRecordingComplete: handleVoiceSubmit,
    });
    const handleVoiceInputPress = handleToggleRecording; // (Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø®ÙˆØ¯ ØªØ§Ø¨Ø¹ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…)

    // --- Attachment Actions ---
    const handleFileSelect = (asset: DocumentPickerAsset | null) => {
        if (asset) {
            setStagedFileState({ asset, status: 'uploading' });
        } else {
            setStagedFileState(null);
        }
    };
    const { handleAttachPress } = useAttachmentPicker({
        setStagedImage,
        setStagedFile: handleFileSelect
    });

    // --- Mic Permission ---
    const requestMicrophonePermission = useCallback(async () => {
        if (Platform.OS === 'android') {
            try {
                const granted = await PermissionsAndroid.request(
                    PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
                    { title: "Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†", message: "...", buttonPositive: "ØªØ§ÛŒÛŒØ¯", buttonNegative: "Ù„ØºÙˆ" }
                );
                return granted === PermissionsAndroid.RESULTS.GRANTED;
            } catch (err) {
                console.warn(err);
                return false;
            }
        } else {
            return true; // iOS permission handled by expo-av
        }
    }, []);

    const handleActivateRealtime = useCallback(async () => {
        const hasPermission = await requestMicrophonePermission();
        if (hasPermission) {
            setMicPermissionGranted(true);
        } else {
            Alert.alert("Ø®Ø·Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ", "Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø¨Ø±Ø§ÛŒ Ú†Øª ØµÙˆØªÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª.");
            if (setSelectedModel) setSelectedModel("gpt-4o-mini");
        }
    }, [requestMicrophonePermission, setSelectedModel]); //...

    //
    // ğŸ›‘ === Ûµ. MESSAGE ACTIONS (Copy, Edit, Regenerate) ===
    //

    const handleCopyMessage = useCallback((text: string) => {
        Clipboard.setString(text);
        Toast.show({ type: 'success', text1: 'Ø¯Ø± Ú©Ù„ÛŒÙ¾â€ŒØ¨ÙˆØ±Ø¯ Ú©Ù¾ÛŒ Ø´Ø¯!' });
    }, []);

    const handleEditMessage = useCallback((msg: IMessage) => {
        setEditText(msg.text);
        setStagedImage(msg.image || null);
        // (Note: File editing not supported in this flow)
        setStagedFileState(null);
    }, []);

    const handleRegenerate = useCallback((messageIndex: number) => {
        const userMessage = messages[messageIndex - 1];
        if (!userMessage || userMessage.user._id !== 1) {
            Toast.show({ type: 'error', text1: 'Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ù‚Ø¨Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯' });
            return;
        }

        // Û±. Ø­Ø°Ù Ù¾ÛŒØ§Ù… Ø±Ø¨Ø§Øª (Ùˆ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Ø¢Ù†)
        setMessages(prev => prev.slice(0, messageIndex));

        // Û². Ø§Ø±Ø³Ø§Ù„ Ù…Ø¬Ø¯Ø¯ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        handleSendMessage(userMessage.text);

    }, [messages, handleSendMessage]); // 'messages', handleSendMessage

    //
    // ğŸ›‘ === Û¶. EFFECTS ===
    //

    // --- Effect: Load chat on ID change ---
    useEffect(() => {
        const chatId = currentChatId;
        const createTimeout = (ms: number, message: string) => new Promise((_, reject) => setTimeout(() => reject(new Error(message)), ms));

        const loadChat = async () => {
            if (isCreatingChatRef.current) {
                setLoadingMessages(false);
                setInitialLoadComplete(true);
                isCreatingChatRef.current = false;
                return;
            }

            if (user && chatId) {
                setLoadingMessages(true);
                setInitialLoadComplete(false);
                try {
                    const loadLogic = async () => {
                        const { data: chatData, error: chatError } = await supabase.from('chats').select('name').eq('id', chatId).single();
                        if (chatError) throw new Error(`Ø®Ø·Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ú†Øª: ${chatError.message}`);
                        setCurrentChatName(chatData?.name || null);
                        await fetchMessages(chatId);
                    };
                    await Promise.race([loadLogic(), createTimeout(10000, 'Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¨ÛŒØ´ Ø§Ø² Û±Û° Ø«Ø§Ù†ÛŒÙ‡ Ø·ÙˆÙ„ Ú©Ø´ÛŒØ¯.')]);
                } catch (error: any) {
                    Toast.show({ type: 'error', text1: 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú†Øª', text2: error.message });
                } finally {
                    setLoadingMessages(false);
                    setInitialLoadComplete(true);
                }
            } else if (!chatId) {
                if (messages.length > 0) {
                    setMessages([]);
                    setCurrentChatName("Ú†Øª Ø¬Ø¯ÛŒØ¯");
                }
                setLoadingMessages(false);
                setInitialLoadComplete(true);
            }
        };

        if (!isLoadingAuth) {
            loadChat();
        }
    }, [currentChatId, user, isLoadingAuth, fetchMessages]); // ...

    // --- Effect: Start file upload ---
    useEffect(() => {
        if (stagedFileState && stagedFileState.status === 'uploading') {
            uploadFile(stagedFileState.asset);
        }
    }, [stagedFileState, uploadFile]);

    // --- Effect: Request mic for realtime ---
    useEffect(() => {
        if (isRealtimeModel(selectedModel) && !micPermissionGranted) {
            handleActivateRealtime();
        } else if (!isRealtimeModel(selectedModel) && micPermissionGranted) {
            setMicPermissionGranted(false);
        }
    }, [selectedModel, handleActivateRealtime, micPermissionGranted, isRealtimeModel]);

    //
    // ğŸ›‘ === Û·. RETURN VALUES ===
    //
    return {
        // --- State & Data ---
        messages,
        stagedFileState,
        stagedImage,
        editText,
        isSending,
        loadingMessages,
        initialLoadComplete,
        isProcessingFile,
        isTranscribing,
        recordingStatus: recordingStatus,
        currentChatName,
        inputKey,
        firstName,
        isRealtime: isRealtimeModel(selectedModel) && micPermissionGranted,
        micPermissionGranted,
        lastUserMessageId,
        lastBotMessageId,
        session, // (Ø¨Ø±Ø§ÛŒ VoiceUI)
        isLoadingAuth, // (Ø¨Ø±Ø§ÛŒ Ù„ÙˆØ¯ÛŒÙ†Ú¯ Ø§ÙˆÙ„ÛŒÙ‡)
        user, // (Ø¨Ø±Ø§ÛŒ Ú†Ú© Ú©Ø±Ø¯Ù† Ù„Ø§Ú¯ÛŒÙ†)

        // --- Action Handlers (Ø¨Ø±Ø§ÛŒ UI) ---
        handleSendMessage,
        handleAttachPress,
        handleVoiceInputPress,
        handleCopyMessage,
        handleEditMessage,
        handleRegenerate,

        // --- Setters (Ø¨Ø±Ø§ÛŒ ChatInput) ---
        onClearStagedImage: () => setStagedImage(null),
        onClearStagedFile: () => setStagedFileState(null),
        onEditTextDone: () => setEditText(null),
    };
};